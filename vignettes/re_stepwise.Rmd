---
title: "re_stepwise"
author: "Robbert Kouwenhoven"
date: "2025-04-13"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries}
library(dplyr)
library(ggplot2)
```

```{r load data}
half_hourly_fluxes <- readr::read_csv("../raw_data/half_hourly_fluxes.csv")
half_hourly_fluxes
tibble::tibble(vars = names(half_hourly_fluxes))

```

```{r clean data}
clean_fluxes <- half_hourly_fluxes %>%
  na.omit()
clean_fluxes
```

```{r bivariate models}
# Get predictor names
predictors <- names(clean_fluxes)[names(clean_fluxes) != "GPP_NT_VUT_REF"]

# Fit bivariate models and store AIC + R²
bivariate_results <- lapply(predictors, function(var) {
  formula <- as.formula(paste("GPP_NT_VUT_REF ~", var))
  model <- lm(formula, data = clean_fluxes)
  data.frame(
    predictor = var,
    AIC = AIC(model),
    R2 = summary(model)$r.squared
  )
})

# Combine results into a data frame
bivariate_models <- do.call(rbind, bivariate_results)

# Plot AIC for each bivariate model
ggplot(bivariate_models, aes(x = reorder(predictor, AIC), y = AIC)) +
  geom_col(fill = "steelblue") +
  coord_flip() +
  labs(x = "Predictor", y = "AIC", title = "AIC of Bivariate Models (p = 2)")

# Plot R² for each bivariate model
ggplot(bivariate_models, aes(x = reorder(predictor, R2), y = R2)) +
  geom_col(fill = "darkgreen") +
  coord_flip() +
  labs(x = "Predictor", y = expression(R^2), title = "R² of Bivariate Models (p = 2)")

```

Part 1 - bivariate models:
This script computes a linear regression using two parameters (and hence 1 variable) for all possible combinations ( = number of variables). For every predictor, a linear model is fitted and AIC + R^2 is computed. Both R^2 and AIC are then visualized for every predictor. As can be seen well in the plots, the predictors corresponding to a high AIC have a low R^2 and vice versa - as expected for a single predictor.

```{r manual greedy stepwise forward regression}
# initial conditions: all predictors are remaining, no predictors are selected, and every new model is better than the current (AIC=infinity)
predictors <- names(clean_fluxes)[names(clean_fluxes) != "GPP_NT_VUT_REF"]
remaining <- predictors
selected <- c()
aic_old <- Inf

# Store AIC and R2 at each step
aic_trace <- data.frame(p = integer(), var_added = character(), R2 = numeric(), AIC = numeric(), stringsAsFactors = FALSE)

repeat {
  cat("\n--- Step", length(selected) + 1, "---\n")
  
  aic_results <- lapply(remaining, function(var) {
    current_vars <- c(selected, var)
    formula <- as.formula(paste("GPP_NT_VUT_REF ~", paste(current_vars, collapse = " + ")))
    
    result <- tryCatch({
      model <- lm(formula, data = clean_fluxes)
      rsq <- summary(model)$r.squared
      aic_val <- AIC(model)
      data.frame(var = var, R2 = rsq, AIC = aic_val)
    }, error = function(e) {
      NULL
    })
    
    return(result)
  })

  # Filter out failed models
  aic_results <- Filter(Negate(is.null), aic_results)

  # Check if anything is left
  if (length(aic_results) == 0) {
    warning("No more valid models could be fitted.")
    break
  }

  # Bind results
  aic_df <- do.call(rbind, aic_results)
  print(aic_df)  # Show R2 and AIC for each variable tested

  best <- aic_df[which.min(aic_df$AIC), ]

  cat("Best variable to add:", best$var, "\n")
  cat("R2:", round(best$R2, 4), "\n")
  cat("AIC (new):", round(best$AIC, 2), "\n")
  cat("AIC (old):", round(aic_old, 2), "\n")

  if (!is.na(best$AIC) && best$AIC < aic_old) {
    selected <- c(selected, best$var)
    remaining <- setdiff(remaining, best$var)
    aic_old <- best$AIC
    aic_trace <- rbind(aic_trace, data.frame(p = length(selected), var_added = best$var, R2 = best$R2, AIC = aic_old))
  } else {
    cat("AIC did not improve. Stopping selection.\n")
    break
  }
}

cat("\nFinal variable selection order:\n")
print(selected)

cat("\nAIC trace:\n")
print(aic_trace)

```

The script performs a stepwise forward regression, aiming to find the best linear model for predicting GPP_DT by incrementally adding predictors that most improve model performance, as measured by the AIC (Akaike Information Criterion).

Here's how it works:

- Initialization: The set of all candidate predictors is stored in remaining. The vector selected starts empty, and aic_old is initialized with infinity to represent the worst possible AIC.

- Iterations inside the repeat loop: At each step, the script evaluates all possible models that add one new predictor from remaining to the current set of selected predictors. For each candidate variable it builds a new formula by combining the selected variables with the current candidate. Then it fits a linear regression model using this formula. The AIC of the model is computed and stored the variable name and AIC in a data frame. Models that fail to fit (due to errors) are skipped using tryCatch().
    
- Model selection: The script identifies the model with the lowest AIC among the candidates. If this new model improves over the previous best AIC (aic_old), it adds the selected variable to the selected list, removes it from remaining, updates aic_old with the new best AIC, and logs the current number of parameters and its AIC in aic_trace.
  
- Stopping criterion: If no improvement in AIC is found (i.e. adding more predictors makes the model worse), the loop stops.

The model with the lowest AIC and its corresponding variables is considered the final (presumably optimal) model.

Printed is for every loop with parameters p what the R^2 and AIC would be with the addition of this new variable from 'remaining'.


```{r visualization + final model}
# Plot
ggplot(aic_trace, aes(x = p, y = AIC)) +
  geom_line() +
  geom_point() +
  labs(title = "AIC vs Number of Predictors",
       x = "Number of Predictors (p)",
       y = "AIC") +
  theme_minimal()

# Final model
final_formula <- as.formula(paste("GPP_NT_VUT_REF ~", paste(selected, collapse = " + ")))
final_model <- lm(final_formula, data = clean_fluxes)
summary(final_model)

```
In the end, only 3 variables out of half_hourly_fluxes are not used. Apparently even using variables like side_ID is able to improve the model. This indicates that there are differences in behaviour of GPP depending on the site, which is not represented in other variables in half_hourly_fluxes. The only variables that won't improve the models performance are the air temperature TA_F and the gapfilled versions of both incoming longwave and shortwave radiation. Note that the not-gapfilled variables LW_IN_F and SW_IN_F are included.
