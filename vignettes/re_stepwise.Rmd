---
title: "re_stepwise"
author: "Robbert Kouwenhoven"
date: "2025-04-13"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries}
library(dplyr)
library(ggplot2)
```

```{r load data}
half_hourly_fluxes <- readr::read_csv("../raw_data/FLX_CH-Lae_FLUXNET2015_FULLSET_HH_2004-2006.csv")
half_hourly_fluxes
tibble::tibble(vars = names(half_hourly_fluxes))

```

```{r clean data}
clean_fluxes <- half_hourly_fluxes %>%
  select(GPP_DT = GPP_DT_VUT_REF, TA_F, SW_IN_F, LW_IN_F, VPD_F, PA_F, P_F, WS_F, SWC_F_MDS_1, SW_IN_POT, WD, USTAR, RH, PPFD_IN, CO2_F_MDS, TS_F_MDS_1) %>%
  na.omit()
clean_fluxes
```

```{r manually add best predictor each round}
# initial conditions: all predictors are remaining, no predictors are selected, and every new model is better than the current (AIC=infinity)
predictors <- names(clean_fluxes)[names(clean_fluxes) != "GPP_DT"]
remaining <- predictors
selected <- c()
aic_old <- Inf

# Store AIC and R2 at each step
aic_trace <- data.frame(p = integer(), var_added = character(), R2 = numeric(), AIC = numeric(), stringsAsFactors = FALSE)

repeat {
  cat("\n--- Step", length(selected) + 1, "---\n")
  
  aic_results <- lapply(remaining, function(var) {
    current_vars <- c(selected, var)
    formula <- as.formula(paste("GPP_DT ~", paste(current_vars, collapse = " + ")))
    
    result <- tryCatch({
      model <- lm(formula, data = clean_fluxes)
      rsq <- summary(model)$r.squared
      aic_val <- AIC(model)
      data.frame(var = var, R2 = rsq, AIC = aic_val)
    }, error = function(e) {
      NULL
    })
    
    return(result)
  })

  # Filter out failed models
  aic_results <- Filter(Negate(is.null), aic_results)

  # Check if anything is left
  if (length(aic_results) == 0) {
    warning("No more valid models could be fitted.")
    break
  }

  # Bind results
  aic_df <- do.call(rbind, aic_results)
  print(aic_df)  # Show R2 and AIC for each variable tested

  best <- aic_df[which.min(aic_df$AIC), ]

  cat("Best variable to add:", best$var, "\n")
  cat("R2:", round(best$R2, 4), "\n")
  cat("AIC (new):", round(best$AIC, 2), "\n")
  cat("AIC (old):", round(aic_old, 2), "\n")

  if (!is.na(best$AIC) && best$AIC < aic_old) {
    selected <- c(selected, best$var)
    remaining <- setdiff(remaining, best$var)
    aic_old <- best$AIC
    aic_trace <- rbind(aic_trace, data.frame(p = length(selected), var_added = best$var, R2 = best$R2, AIC = aic_old))
  } else {
    cat("AIC did not improve. Stopping selection.\n")
    break
  }
}

cat("\nFinal variable selection order:\n")
print(selected)

cat("\nAIC trace:\n")
print(aic_trace)

```

The script performs a stepwise forward regression, aiming to find the best linear model for predicting GPP_DT by incrementally adding predictors that most improve model performance, as measured by the AIC (Akaike Information Criterion).

Here's how it works:

- Initialization: The set of all candidate predictors is stored in remaining. The vector selected starts empty, and aic_old is initialized with infinity to represent the worst possible AIC.

- Iteration (inside the repeat loop): At each step, the script evaluates all possible models that add one new predictor from remaining to the current set of selected predictors.
  For each candidate variable:
    - It builds a new formula by combining the selected variables with the current candidate.
    - It fits a linear regression model using this formula.
    - It calculates the AIC of the model and stores the variable name and AIC in a data frame.
    - Models that fail to fit (due to errors) are skipped using tryCatch().
    
- Model selection: The script identifies the model with the lowest AIC among the candidates. If this new model improves over the previous best AIC (aic_old), it:
  - Adds the selected variable to the selected list,
  - Removes it from remaining,
  - Updates aic_old with the new best AIC,
  - And logs the current number of parameters and its AIC in aic_trace.
  
- Stopping criterion: If no improvement in AIC is found (i.e. adding more predictors makes the model worse), the loop stops.

The model with the lowest AIC and its corresponding variables are considered the final (presumably optimal) model.


The repeat loop first checks if there are any predictors left. It keeps on trying to improve the model by adding another predictor. Then, for every remaining variable, the script creates a new model formula by adding the new variable to the already existing set of predictors, it fits a linear regression, calculates the AIC of that model and finally stores the results - i.e. the fit + the AIC - in a data frame called aic_df. After that, the code finds the best result (minimum AIC). If this new best model is better than the previous one, the predictor is moved from 'remaining' to 'selected' as long as the newer models keep on improving. If it no longer does this, we've found the best model and the loop is stopped.

```{r visualization + final model}
# Plot
ggplot(aic_trace, aes(x = p, y = AIC)) +
  geom_line() +
  geom_point() +
  labs(title = "AIC vs Number of Predictors",
       x = "Number of Predictors (p)",
       y = "AIC") +
  theme_minimal()

# Final model
final_formula <- as.formula(paste("GPP_DT ~", paste(selected, collapse = " + ")))
final_model <- lm(final_formula, data = clean_fluxes)
summary(final_model)

```

